# Ensemble Methods for Machine Learning Classification

A comprehensive machine learning project implementing and comparing Random Forest, AdaBoost, and Gradient Boosting algorithms with advanced techniques for handling imbalanced data and model interpretability.

##Project Overview

This project explores ensemble learning techniques for classification tasks, with a focus on:
- Comparative analysis of three major ensemble algorithms
- Handling imbalanced datasets using SMOTE
- Model interpretability using LIME
- Comprehensive performance evaluation

## Key Features

- **Multiple Ensemble Algorithms**: Random Forest, AdaBoost, and Gradient Boosting
- **Imbalanced Data Handling**: Implementation of SMOTE (Synthetic Minority Over-sampling Technique)
- **Model Interpretability**: LIME (Local Interpretable Model-agnostic Explanations) for understanding predictions
- **Comprehensive Evaluation**: ROC curves, AUC scores, precision, recall, and F1 metrics
- **Feature Importance Analysis**: Comparison across different models

##Technologies Used

- **Python 3.8+**
- **scikit-learn** - For machine learning algorithms
- **pandas** - Data manipulation
- **numpy** - Numerical operations
- **matplotlib** - Data visualization
- **imbalanced-learn** - SMOTE implementation
- **lime** - Model interpretability

